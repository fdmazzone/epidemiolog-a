\documentclass[a4paper,10pt]{article}
\usepackage[utf8]{inputenc}
\usepackage{amsmath, amsthm, amssymb}
\usepackage{color}
\usepackage{systeme}
\usepackage[utf8]{inputenc}
\usepackage{empheq}
\usepackage{bbm}
\usepackage{cite}
\usepackage{todonotes}
 \usepackage{empheq}
\usepackage{fixme} 
\usepackage{mathrsfs}
 
\newtheorem{thm}{Theorem}[section]
\newtheorem{cor}[thm]{Corollary}
\newtheorem{lem}[thm]{Lemma}
\newtheorem{rem}[thm]{Remark}
\newtheorem{exa}[thm]{Example}
\newtheorem{defn}[thm]{Definition}
\newtheorem{conj}[thm]{Conjecture}
\newtheorem{prop}[thm]{Proposition}
\theoremstyle{remark}
\newtheorem{comentario}{Remark}


\newcommand{\bm}[1]{\boldsymbol{#1}}

%opening
\title{An optimal control problem for a metapopulation SIR model with vaccination}
\author{}




\begin{document}

\maketitle

\begin{abstract}

\end{abstract}


\section{Introduction}


The study of the dynamics of epidemics by means of mathematical models is an active area of scientific research \cite{LindaS.Allen486,FredBrauer478,FredBrauer479,MaiaMartcheva480,FredBrauer482}. The spread of diseases is an extremely complex social and biological process. Countless factors come into play, such as the habits of societies, the level of contact between individuals, public strategies for control and mitigation of epidemics, population structure, information campaigns, demographic changes, migrations, etc. Obviously, to this must be added,   those factors based on the interaction between pathogens and the immune system and the evolutionary dynamics of the latter.

It is not easy, and perhaps not even useful, to build models that address all of these factors simultaneously. A complex model is more difficult to analyze mathematically and consequently it may not be easy to draw conclusions from it. On the other hand, the practical implementation of mathematical models requires having information about the object to be studied, for example model parameters. These parameters are usually estimated from the comparison between quantities that can be effectively observed and measured in reality and that in turn can be calculated by the model. This fit of the model to the observation may require information that is not available for a complex model.

The goals of mathematical modeling are also multiple. An issue in which this area of science can help is in providing criteria for decision making, fundamentally when these decisions involve the distribution of resources that are scarce. 

\todo{Me parece que sería bueno mencionar algo sobre modelos compartimentados y SIR}

In this article we are interested in the dynamics of epidemics in heterogeneous populations. Heterogeneity means that individuals do not behave in the same way with respect to the progress of the epidemic, and that the differences affect the dynamics of the process. Therefore, assuming  homogeneity can lead to inaccuracies. The simplest example of this situation is when a disease is transmitted through a network of clusters of spatially separated individuals. It is known that the transmission of many diseases depends on the amount of contact between individuals. In a population separated into clusters, the rate of contact of an individual with others in the same cluster is, of course, to be expected to be different from that with individues  in other clusters. But even in populations that are not spatially separated, it may be the case that individuals fulfill different roles within society, which would allow classify   them into different groups with specific contact rates.
The approach that we will follow in this article is known in the literature as the metapopulation models  or models with
patchy environments and movement between patches \cite{FredBrauer482}.

Vaccines are one of the most effective resources to mitigate the incidence of diseases. On some occasions, for example in a severe
disease outbreaks,  the supply of vaccines is limited and a decision must be made on how to distribute them.  The objective of this article is to apply the mathematical theory of optimal control to the problem of determining the most efficient way to distribute a supply of vaccines within a metapopulation model. The global vaccination rate will be assumed to be a known function of time and the problem consists of how to distribute the vaccines in such a way as to minimize "cost". In this article we consider minimizing the total number of infected throughout the history of the epidemic.



We are going to briefly describe some scientific literature where problems similar to those dealt with in this article were addressed.

 
The so-called complex network epidemiological models \cite{Pastor-Satorras2001,Pastor-Satorras2001b}  have received attention in the past. In these models each individual represents a node in a graph. The population is divided into compartments, composed of susceptible individuals, infected individuals, etc. In turn, the total population is divided according to the degree (number of neighbors) of the individual-nodes. The result is a model equivalent in certain respects to the one proposed in this article. The fact of structuring the population according to the degree of connectivity of individuals allows  to analyze how this connectivity affects the spread of the disease. The analysis of control strategies (quarantine, vaccination, treatment, etc.) on complex networks has been studied in \cite{KANG20173945, Esquivel-Gomez2018,Strona2018,Pastor-Satorras2002,Kalisky2004, Nowzari2016} to cite some background. 

More specifically, in \cite{rowthorn2009optimal,asano2008optimal, mbah2011resource,Chen-2014,Chen-2014b}  problems of optimal control over networks-metapopulations were addressed.
In \cite{rowthorn2009optimal} a optimal control problem for a metapopulation SIS model with two subpopulations was studied.  The control strategies considered included treatment of the disease and restrictions on interpopulation circulation, quarantine controls that
restrict the reciprocal rate of cross infection between
the two regions. In \cite{asano2008optimal} a problem similar to the one considered in this article was studied, i.e. a problem  where vaccine doses must be distributed in a network. The objective function used in \cite{asano2008optimal} accounts for the total number of individuals who were infected and the cost of the vaccination process.  In \cite{Li-2019} was studied an optimal control problem in a metapopulation  SIQS quarantine controled  model. In \cite{mbah2011resource} was considered optimal control in a metapopulation  SIR model with   treatment and state variable constraints. 
In \cite{Chen-2014,Chen-2014b} optimal control in a metapopulation  SIR model with   treatment and vaccination
 
 One of the main differences between previous papers  and this article is that we do not consider that access to the provision of vaccines is  limited by their cost, but rather vaccine supply is limited. We assume given the quatity of vaccines per unit time   for the entire network. This leads us to what in optimal control theory is called mixed variable state constraints. In \cite{mbah2011resource, rowthorn2009optimal} variable state constraint are introduced for  treatment control optimal problems.  

 
 \todo[inline]{Es un super-borrador de introducción. Hay que trabajar mucho en mejorar  la redacción y desarrollar un poca más.} 

 
\section{The mathematical model}


\subsection{Description and consistency}
By ``consistency'' we mean that the model has a unique solution and  that it produces predictions  for the variables according to their biological meaning.

We will assume a population of $N$ individuals  with the same birth and death rate $\mu\geq 0$.  Let us suppose that this population is divided into $n$ subpopulations (or nodes) according to a certain criterion (geographic, social activity, number of links in a graph of a complex network, etc). We further divide each subpopulation into susceptible, infected and immunized individuals, $S_i$, $I_i$ and $R_i$ respectively. We consider the following network-based SIR epidemic model:

\begin{empheq}[left=\empheqlbrace,]{align}\label{eq:ModeloSIR1}
    S'_{i}(t)&=\mu N_i-S_{i}(t) \sum\limits_{j=1}^{n} \beta_{i j} I_{j}(t)-  (u_{i}(t) +\mu) S_{i}(t)+\alpha R_i(t)  \\ \label{eq:ModeloSIR2}
    I'_{i}(t)&=S_{i}(t) \sum\limits_{j=1}^{n} \beta_{i j} I_{j}(t)-(\mu+\gamma) I_{i}(t)  \\ \label{eq:ModeloSIR3}
    R'_{i}(t)&=\gamma I_{i}(t)+  u_{i}(t) S_{i}(t)-(\mu+\alpha) R_{i}(t)  
\end{empheq}
where     $1=1,\ldots , n$ and $N_i=S_i+I_i+R_i$ is the total poblation of node $i$.   The parameters in the model have the following meanings: $\beta_{ij}\geq 0$ are the transmission rate of infect individuals from patch $j$ to susceptible individuals in patch $i$;   $ u_{i}(t)\geq 0$ (control variable) is the vaccination rate in node $i$ at time $t$;  $\gamma^{-1} >0$  is the infectious period and $\alpha^{-1} >0$  is the immunity period ( we agree that $\alpha^{-1}=\infty$ when $\alpha=0$).

We observe that summing, for each $i$, the  equations \eqref{eq:ModeloSIR1}-\eqref{eq:ModeloSIR3} we obtain $N'_i(t)=0$, i.e. $N_i$ is time independent. Consequently we can drop equation \eqref{eq:ModeloSIR3} in the system. Consequently, in this article we use the following state equations

\begin{empheq}[left=\empheqlbrace]{align}\label{eq:ModeloSIRb1}
    S'_{i}(t)&=(\mu+\alpha) N_i-S_{i}(t)\left[ \sum\limits_{j=1}^{n} \beta_{i j} I_{j}(t)+ u_{i}(t) +\mu+\alpha\right] -\alpha I_i(t)\tag{$SIR_1$} \\ \label{eq:ModeloSIRb2}
    I'_{i}(t)&=S_{i}(t) \sum\limits_{j=1}^{n} \beta_{i j} I_{j}(t)-(\mu+\gamma) I_{i}(t)\tag{$SIR_2$} 
\end{empheq}



\begin{figure}[h]
\begin{center}
\def\svgwidth{9cm}
\input{SIR_vacuna.pdf_tex}
\caption{Flow chart model \eqref{eq:ModeloSIR1}-\eqref{eq:ModeloSIR3}}\label{fig:flow_chart}
\end{center}
\end{figure}

In order to address optimal control problems, the control variables $u_i$   are usually assumed to be in the space $L^{\infty}$, and thus possibly these functions are not smooth. Hence, it is pertinent to explain in what sense the  functions $S_i$ and $I_i$, $i=1,\ldots,n$ are solutions of \eqref{eq:ModeloSIRb1}-\eqref{eq:ModeloSIRb2}. We must also discuss the conditions under which the initial value problem, associated to the equations \eqref{eq:ModeloSIRb1}-\eqref{eq:ModeloSIRb2}, is well-possed.  

We will adopt the convention of using boldface symbols to denote objects such as vectors and matrices.
Thus, for example, $\bm{\beta}$ denotes matrix $\{\beta_{ij}\}_{i,j=1}^n$, $\bm{S}=(S_1,\ldots,S_n)$ and so on. Given two arrays $\bm{A}$ and $\bm{B}$ we denote by $\bm{A}\times \bm{B}$ the element  wise product of $\bm{A}$ and $\bm{B}$. We write $\bm{x}=(\bm{S},\bm{I})$ and

\[
    \begin{split}
     \bm{f}_{\bm{S}}&=(\mu+\alpha)\bm{N}-\bm{S}\times (\bm{\beta}\bm{I}+\bm{u})-(\mu+\alpha)\bm{S}-\alpha\bm{I},\\
     \bm{f}_{\bm{I}}&=\bm{S}\times \bm{\beta}\bm{I}-(\mu+\gamma)\bm{I},\\
     \bm{f}&=(\bm{f}_{\bm{S}},\bm{f}_{\bm{I}}),
     \end{split}
\]
where $\bm{\beta}\bm{I}$ denotes the usual matrix-vector product.

Then the  system  \eqref{eq:ModeloSIRb1}-\eqref{eq:ModeloSIRb2} is written in compact form $\bm{x}'=\bm{f}(\bm{x},t)$. Given $\bm{x}_0\in\mathbb{R}^{2n}$ we have the corresponding initial value problem

\begin{empheq}[left=\empheqlbrace]{equation}\label{eq:sist_compact}
\begin{split}
 \bm{x}'&=\bm{f}(\bm{x},t).\\
 \bm{x}(0)&=\bm{x}_0
\end{split}\tag{$E$}
\end{empheq}

One aspect that should be noted and that is often neglected in the literature is the fact that the vector field $\bm{f}$ is not continuous. This is because in optimal control problems it is usually assumed that the control functions $u_i$ are in the space $L^\infty$. Fortunately, we can deal with this type of equations by means of Carathéordory theory  \cite{A.F.Filippov512,EarlA.Coddington236} of differential equations.
 
Following \cite{A.F.Filippov512} we said that  $\bm{x}$ is a \emph{solution} of \eqref{eq:sist_compact} on an  interval $[0,a)$ if and only if $\bm{x}$ is absolutely continuous on each subinterval $[0,c]\subset [0,a)$, it satisfies initial condition and $\bm{x}'=\bm{f}(\bm{x},t)$  for almost everywhere $t\in (0,a)$.   Alternatively, it is equivalent to say that $\bm{x}$ satisfies the integral equation 

\begin{empheq}{equation}\label{eq:eq_integral}
 \bm{x}(t)=\bm{x}_0+\int_0^t\bm{f}(\bm{x},t)dt.
\end{empheq}




We note that if $u_i\in L^1([0,+\infty))$ then $\bm{f}$ is a Carathéodory function in the sense of \cite[p. 3]{A.F.Filippov512} on the domain $\Omega\times[0,+\infty)$, where $\Omega$ is an open and bounded set in $\mathbb{R}^{2n}$. That means, $\bm{f}(\bm{x},t)$ is continuous in $\bm{x}$ for almost everywhere $t\in[0,+\infty)$,  $\bm{f}(\bm{x},t)$ is measurable in $t$ for each $\bm{x}\in\Omega$ and there exists $m\in L^1([0,+\infty))$ such that $|\bm{f}(\bm{x},t)|\leq m(t)$ for every $(\bm{x},t)\in \Omega\times[0,+\infty)$.   Consequently we can apply  existence and uniqueness theory for Carathéodory equations \cite[Th. 1, p. 4, Th. 2, p. 5]{A.F.Filippov512}, \cite[Th. 1.1]{EarlA.Coddington236},  we conclude that for any $\bm{x}_0\in \Omega$ there exists a unique local solutions of the  boundary value problem \eqref{eq:sist_compact}  defined in some interval  $[0,\delta)$, $\delta>0$.  




We will use the following well known and elementary formula for the solution of a linear scalar equation of first order $x'(t)+p(t)x(t)=q(t)$:
\begin{equation}\label{eq:1order}
 x(t)=e^{-\int_0^tp(s)ds}\left\{x(0)+\int_0^t e^{\int_0^sp(r)dr}q(s) ds \right\}.
\end{equation}

For $i=1,\ldots,n$ it is convenient to set
\[
 \Theta_i(t):=\sum\limits_{j=1}^{n} \beta_{i j} I_{j},\quad\nu=\mu+\alpha.
\]
Then using formula \eqref{eq:1order} we obtain that equations \eqref{eq:ModeloSIRb1}-\eqref{eq:ModeloSIRb2} and \eqref{eq:ModeloSIR3} are equivalent to the integral equations

\begin{empheq}{multline}\label{eq:eq_integralS}
S_i(t)= \exp\left\{-\nu t- \int_0^t\Theta_i+u_ids\right\}S_i(0)\\
    + 
    \int_0^t \exp\left\{
            \nu (s-t)+\int_t^s\Theta_i+u_idr
            \right\} 
            \left(
                \nu N_i-\alpha I_i
            \right)
            ds 
\end{empheq}

\begin{empheq}{multline}\label{eq:eq_integralI}
I_i(t)= \exp\left(- (\mu+\gamma)t \right)
\left\{  
    I_i(0)+ 
    \int_0^t \exp\left(
            (\mu+\gamma)s\right) 
            \Theta_iS_i
            ds
\right\} 
\end{empheq}

\begin{empheq}{multline}\label{eq:eq_integralR}
R_i(t)= \exp\left(- (\mu+\alpha)t \right)
\left\{  
    R_i(0)+ 
    \int_0^t \exp\left(
            (\mu+\alpha)s\right) 
            (\gamma I_i +u_iS_i)
            ds
\right\} 
\end{empheq}

Equations \eqref{eq:eq_integralS}-\eqref{eq:eq_integralI} have the advantage that they are valid for every $t\geq 0$  while the equations \eqref{eq:ModeloSIRb1}-\eqref{eq:ModeloSIRb2} holds true almost everywhere. 

Although the problem \eqref{eq:sist_compact} makes mathematical sense for any $\bm{x}$ it is only relevant, from an epidemiological point of view, in the closed set
\[
 \Omega_0=\left\{\bm{x}\in\mathbb{R}^{2n}|  0\leq x_i,x_{n+i}\leq N_i, i=1,\ldots,n\right\}.
\]
% Since  $\nu N_i-\alpha I_i\geq 0$, we obtain from equations \eqref{eq:eq_integralS}-\eqref{eq:eq_integralI}  that $S_i(t), I_i(t)\geq 0$ for every $t$ where solutions are defined. On the other hand, $S_i(t)+I_i(t)\leq   N_i$. Consequently, the set $\Omega$ is flow invariant for the equation \eqref{eq:sist_compact}.  If $\Omega$ is any bounded an open set containing $\Omega_0$ and $\bm{x}_0\in\Omega_0$ we have that the solution $\bm{x}(t)$ of \eqref{eq:sist_compact} remains inside $\Omega$ for every $t>0$ where solution is defined.  We infer using continuation theory \cite[Th. 1.3]{EarlA.Coddington236} that the solition is defined for every positive time.  


\subsection{Propagation on the network}

 


In this section we aim to demonstrate a result concerning the spread of infection in the network.
% We begin this section by establishing a result which guarantees that if  $S_i$ and $I_i$, with $i=1,2,\ldots,n$, are solution of the system of equations \eqref{eq:ModeloSIRb1}, \eqref{eq:ModeloSIRb2},  and satisfy that  $S_i(0)\geq 0$ and $I_i(0)\geq 0$ then  $S_i$ and $I_i(t)\geq 0$ 


% \begin{prop}\label{proposicion:Si=>0-Ii=>0} Let $S_i$ and $I_i$, with $i=1,2,\ldots,n$, solutions of the system of equations \eqref{eq:ModeloSIRb1} \eqref{eq:ModeloSIRb2}, such that satisfy   $S_i(0)\geq 0$ and $I_i(0)\geq 0$, then  $S_i(t)\geq 0$ and $I_i(t)\geq 0$ for all $t\in (0,+\infty)$.
% \end{prop}
% \begin{proof}

% %  Let $C_1:=\{(S,I)\in\mathbb{R}^{2n}:S_i\geq 0, I_i\geq 0, \ \text{for}\ i=1,2,\ldots,n\}$. By THEOREM ?? in ?? we should prove that for every $(S,I)\in C_1$ the equality
% %  \begin{equation*}
% %      \lim\limits_{h\searrow 0}\frac{d((S,I)+h\bm{f}(S,I),C_1)}{h}=0
% %  \end{equation*}
% %  is satisfied, where $d$ is the Euclidean distance in $\mathbb{R}^{2n}$. In fact, due to the expression of $\bm{f}=(\bm{f_1},\bm{f_2})$ we can conlude that for fixed $(S,I)\in C_1$ there exist $\delta>0$ such that if $0<h<\delta$ then $(S,I)+h\bm{f}(S,I)\in C_1$. Therefore the above equality is satisfied.
% \end{proof}


The following conjecture states that if $\bm{\beta}$ is an irreducible matrix then the epidemic is transmitted from any node to the rest with infinite speed.
Next we give the definition of irreducible matrix and establish a result that will be useful to probe the mentioned conjecture. 

\begin{defn}[Reducible and Irreducible matrix]
Let $\bm{\Psi}=\{\psi_{ij}\}_{i,j=1}^n$ be a real matrix. We say $\bm{\Psi}$ is \textbf{reducible} if there exist a permutation matrix $\bm{P}$ such that $\bm{P}^{T}\bm{\Psi}\bm{P}=\left(\begin{array}{cc}
     \bm{X}  & \bm{Y}\\
     \bm{0} &  \bm{Z}
\end{array}\right)$, where $\bm{X}$ and $\bm{Z}$ are both square matrices. If $\bm{\Psi}$ is not \textbf{reducible} then it is \textbf{irreducible}.
\end{defn}

\begin{lem}\label{lema:Psi.irredusible<-->Grafofuert.conectado}
Let $\bm{\Psi}=\{\psi_{ij}\}_{i,j=1}^n$ be a real matrix. Then, $\bm{\Psi}$ is irreducible if and only if for every pair $(i,j)$, with $1\leq i,j\leq n$ there exists $k_1,k_2,\ldots,k_m\in \{1,2,\ldots,n\}$ such that $\psi_{ik_1}\neq 0$, $\psi_{k_lk_{l+1}}\neq 0$ for $l=1,2,\ldots,m-1$, and $\psi_{k_mj}\neq 0$.
\end{lem}


% From equations \eqref{eq:ModeloSIR1}, \eqref{eq:ModeloSIR2} and \eqref{eq:ModeloSIR3} we have that $N_i':=(S_i+I_i+R_i)'=0$, i.e. the total population of node $i$ remain constant. Cosequently $R_i=N-S_i-I_i$ and  we can drop the equation for $R_i$  of the system. Therefore, we can study the SIR metapopulation model with vaccination (SIRmv) system.

%   \begin{empheq}[left=\empheqlbrace]{align}
%  S'_{i} &= -S_{i}(t) \sum\limits_{j=1}^{n} \beta_{i j} I_{j}(t)-   u_{i}(t) S_{i}(t)\label{eq:ModeloSIRb1b}\tag{SIRmv1}\\
%  I'_{i}&=S_{i}(t) \sum\limits_{j=1}^{n} \beta_{i j} I_{j}(t)-\gamma I_{i}(t)
%  \label{eq:ModeloSIRb2b}\tag{SIRmv2}
%   \end{empheq}

  
% We  note that the system of equations \eqref{eq:ModeloSIRb1}, \eqref{eq:ModeloSIRb2} possibly has a discontinuous right hand side. I this case,  I this case, following to \cite{A.F.Filippov512}. \textcolor{red}{Poner el significado de solución} 
  


%CTRL+SHIFT+7 para comentar y descomentar

% From  \eqref{eq:ModeloSIRb1}, \eqref{eq:ModeloSIRb2} and \eqref{eq:1order} we obtain that

% \[
%  S_i(t)=S_i(0)
%  \exp\left(
%     -\int_0^t\sum\limits_{j=1}^{n} \beta_{i j} I_{j}(s)+ u(s)ds
%     \right)
% \] 
% and

% \[
%  I_i(t)=e^{-\gamma t}\left(I_i(0)+\int_0^te^{\gamma s}S_i(s)\sum_{j=1}^n\beta_{ij}I_j(s)ds\right)
% \] 



 

\begin{prop} Suppose that $\beta$ is a irreducible matrix. If $S_i(0)\geq 0$, $I_i(0)\geq 0$, $R_i(0)\geq 0$ for every $i\in\{1,2,\ldots,n\}$ and there exists $i_0$ such that $I_{i_0}(0)>0$ then for every $i=1,2,\ldots,n$ and $t>0$ we have that $S_i(t)>0$, $I_i(t)>0$ and $R_i(t)>0$; except in the exceptional case that  $\mu=0$, $\alpha=0$ and  there exists $i'$ such that $S_{i'}(0)=I_{i'}(0)=0$, in which case  
$S_{i'}(t)=0$ and $I_{i'}(t)=0$ for all $t\geq 0$.
\end{prop}
 
\begin{proof} \todo[inline]{Hay que repensar la demostración para admitir soluciones que no son derivables. Hay que utlizar ecuaciones \eqref{eq:eq_integralS} -\eqref{eq:eq_integralI}.  Hagamos la demostración para el modelo full- demografía y reinfecciones. Ojo! hay un caso excepcional, cuando no hay demografía ($\mu=0$), no hay reinfección ($\alpha=0$) e inicialmente todos son recuperados $R_i(0)=N_i$}



Let's start with the exceptional case where that $\mu=0$ and $\alpha=0$ there exists $i'$ such that $S_{i'}(0)=I_{i'}(0)=0$. In this case, we have that the corresponding equations \eqref{eq:ModeloSIRb1} and \eqref{eq:ModeloSIRb2} for $i=i'$ are satisfied by choosing $S_{i'}\equiv 0$ and $I_{i'}\equiv 0$;  thus, in addition, for the other values of $i\neq i'$ we can eliminate the term $\beta_{ii'}I_{i'}(t)$ of the sums in the equations \eqref{eq:ModeloSIRb1} and \eqref{eq:ModeloSIRb2}. That is, we can remove the functions $S_{i'}$ and $I_{i'}$ from the system of equations \eqref{eq:ModeloSIRb1}, \eqref{eq:ModeloSIRb2} and it will be the same as before but with $n-1$ populations. Solving it we obtaining functions $S_{i}$ and $I_i$, for $i\in\{1,2,\ldots,i'-1,i'+1,\ldots n\}$, by adding to these the functions $S_{i'}\equiv 0$ and $I_{i'}\equiv 0$, we obtain a solution of the initial system \eqref{eq:ModeloSIRb1}, \eqref{eq:ModeloSIRb2} with $n$ populations.

Taking into account what we have mentioned above, we can assume from now on that $\mu>0$, or $\alpha>0$, or for all $i\in\{1,2,\ldots,n\}$ it is satisfied that $S_i(0)\neq 0$ or $I_i(0)\neq 0$.

% Before starting to analyze the previous cases note first that if $S_{i}(t)>0$ and $I_i(t)>0$ for every $i\in\{1,2,\ldots,n\}$ and $t\in (0,\delta)$, with $\delta>0$, then $S_i(t)>0$ and $I_i(t)>0$ for all $t\in (0,+\infty)$. In fact, if the last statement were not true taking 

Let us consider the set
$$A:=\{t\in (0,+\infty): S_i(t)\leq 0\ \text{or}\ I_i(t)\leq 0,\ \text{for some}\ i=1,2,\ldots,n\}.$$
It is sufficient to show that $A=\emptyset$. 

Suppose that $A\neq \emptyset$ and define $t_0:=\inf A$.
Note that  $S_j(t_0)=0$ or $I_j(t_0)=0$ for some 
$j\in\{1,2,\ldots,n\}$.  We have two cases. 

\emph{Case $t_0>0.$} In this situation we have that $S_i(t)>0$ and $I_i(t)>0$ for all $t\in (0,t_0)$ and every $i=1,2,\ldots,n$. Since $\boldsymbol{\beta}$ is an irreducible matrix we have that for every $i\in\{1,2,\ldots,n\}$ there exist $j_i$ such that $\beta_{i,j_i}>0$. Then $\Theta_i>0$ on $(0,t_0)$, which implies that the integrand in \eqref{eq:eq_integralI} is strictly positive on $(0,t_0)$. In a similar way we can conclude the same for the integrand in \eqref{eq:eq_integralR}. On the other hand the term $\nu N_i-\alpha I_i$ is also positive on $(0,t_0)$. Thus $S_j(t_0)>0$ and $I_j(t_0)>0$, which is a contradiction.



Suppose that $\mu>0$, as $S_i(0)\geq 0$ for every $i\in\{1,2,\ldots,n\}$ then, by formula \eqref{eq:eq_integralS}, we have that there exists $\delta_1>0$ such that $S_i(t)>0$ for all $t\in (0,\delta_1)$ and every $i\in\{1,2,\ldots,n\}$.  Defining the set $Q_1:=\{i\in\{1,2,\ldots,n\}:\beta_{i i_0}>0\}$, as the matrix  $\{\beta_{ij}\}$ is  irreducible, by Lemma \ref{lema:Psi.irredusible<-->Grafofuert.conectado}, we have that $Q_1\neq \emptyset$. For fixed $i\in Q_1$ we have that $\Theta_i(t)>0$ for all $t\in (0,\delta_i)$ with $\delta_i>0$, and thus $I_i(t)>0$ for all $t\in (0,\delta_i)$.  Considering, for $k\geq 2$, the set $Q_k:=\{i\in \{1,2,\ldots,n\}: i\notin \cup_{j=1}^{k-1}Q_j\ \text{and}\ \exists j_0\in Q_{k-1}\ | \beta_{i(k-1)}>0 \}$, reasoning as we did before, and through an induction process, we can see that if  $i\in Q_l$, for some $l$, then $I_i(t)>0$  for all $t\in (0,\delta_l)$ with $\delta_l>0$. As the matrix $\{\beta_{ij}\}$ is irreducible we have that for every $i\in \{1,2,\ldots,n\}$ there exist $l\in\mathbb{N}$ such that $i\in Q_l$. Thus we can assure that $I_i(t)>0$ for all $t\in (0,\tilde{\delta})$, with $\tilde{\delta}>0$, and every $i\in \{1,2,\ldots,n\}$. By the assertion in the previous paragraph  we have that $I_i(t)>0$ for every $t\in (0,+\infty)$ and  $i\in \{1,2,\ldots,n\}$.

Let's suppose that $\alpha>0$. If $S_i(0)=0$ and $I_i(0)<N_i$ then, by formula \eqref{eq:eq_integralS} we have that $S_i(t)>0$ for $t\in (0,\delta)$, for some $\delta>0$.  If  $S_{i}(0))=0$ and $I_{i}(0)=N_i$ then also $S_i(t)>0$ for $t$ close to zero, since if  $S_i\leq 0$ near to zero then, by formula \eqref{eq:eq_integralI} we have that $I_i(t)<0$ for $t$ close to zero, which implies, by \eqref{eq:eq_integralS}, that $S_i>0$ near to zero, and this is an absurd. Therefore there exists $\delta>0$ such that $S_i(t)>0$ for all $t\in (0,\delta)$ and $i\in\{1,2,\ldots,n\}$. Now, reasoning as we did in the previous paragraph we have that $I_i(t)>0$ for $t$ close to zero and every $i=1,2,\ldots,n$. Thus, $I_i(t)>0$ for every $t\in (0,+\infty)$ and  $i\in \{1,2,\ldots,n\}$.

By last, suppose that for all $i\in\{1,2,\ldots,n\}$ it is satisfied that $S_i(0)\neq 0$ or $I_i(0)\neq 0$. Similarly to how we did in the previous paragraph we can see that $S_i(t)>0$ and $I_i(t)>0$ for $t$ close to zero, which implies that $I_i$ is a positive function in $(0,+\infty)$ for every $i\in\{1,2,\ldots,n\}$.




% Since $I_{i_0}(0)>0$ there exists $\delta_2>0$ such that $\Theta_i(t)>0$ for all $t\in (0,\delta_2)$ and $i\in\{1,2,\ldots,i_0-1,i_0+1,\ldots n\}$, thus from formula \eqref{eq:eq_integralI} we have that $I_i(t)>0$ for all $t\in (0,\delta)$ and $i\in\{1,2,\ldots,n\}$, with $\delta=\min\{\delta_1,\delta_2\}$. Taking account the assertion in the previous paragraph we have that $I_i(t)>0$ for every $i\in\{1,2,\ldots,n\}$ and $t\in (0,\delta)$.
  



% Let us prove the conclusion of the proposition.   
% Defining the set $Q_1:=\{i\in\{1,2,\ldots,n\}:\beta_{i i_0}>0\}$, as the matrix  $\{\beta_{ij}\}$ is  irreducible, by Lemma \ref{lema:Psi.irredusible<-->Grafofuert.conectado}, we have that $Q_1\neq \emptyset$. For fixed $i\in Q_1$, if $I_i(0)>0$ then, by formula \eqref{eq:eq_integralI} and Proposition \ref{proposicion:Si=>0-Ii=>0} , we have that $I_i(t)>0$ for all $t\in (0,+\infty)$; on the other hand if $S_i(0)>0$  then, by formula \eqref{eq:eq_integralS},  we have that $S_i(t)>0$ for all $t\in (0,+\infty)$, and by Proposition \ref{proposicion:Si=>0-Ii=>0}, the fact that $\beta_{i i_0}>0$, $I_{i_0}(t)>0$ for every $t\in (0,+\infty)$ and formula \eqref{eq:eq_integralI} we conclude  that $I_i(t)>0$ for all $t\in (0,+\infty)$.

% Considering the set $Q_2:=\{i\in\{1,2,\ldots,n\}:i\notin Q_1\ \text{and}\ \exists j_0\in Q_1\ | \ \beta_{ij_0}>0 \}$. Reasoning as we did in the previous paragraph we have that for $i\in Q_2$ $I_i(t)>0$ for all $t\in (0,+\infty)$. Defining $Q_k:=\{i\in \{1,2,\ldots,n\}: i\notin \cup_{j=1}^{k-1}Q_j\ \text{and}\ \exists j_0\in Q_{k-1}\ | \beta_{i(k-1)}>0 \}$, and reasoning as we did before we have that if  $i\in Q_l$, for some $l$, then $I_i(t)>0$  for all $t\in (0,+\infty)$. As the matrix $\{\beta_{ij}\}$ is irreducible we have that for every $i\in \{1,2,\ldots,n\}$ there exist $l\in\mathbb{N}$ such that $i\in Q_l$, and therefore $I_i(t)>0$ for every $t\in (0,+\infty)$.
% Let $i,j\in \{1,2,\ldots,n\}$ such that $I_i(0)>0$ and $i \neq j$. 

% Suppose first that $\beta_{ij}>0$. 
% Let's fix $\epsilon>0$ and see that $I_j(t)$ is positive for all  $t>\epsilon$. As $I_i(0)>0$ then $I_i(\epsilon)>0$. For $t>\epsilon$ we have that
% \begin{equation*}
% I_j(t)=e^{-\int_{\epsilon}^{t}(\gamma-\beta_{jj}) ds}\left(I_j(\epsilon)+\int_{\epsilon}^{t}e^{\int_{\epsilon}^{s}(\gamma-\beta_{jj}) dz}\left[S_j(s)\sum_{k=1,k\neq j}^{n}\beta_{jk}I_k(s)\right]ds\right).
% \end{equation*}
% Let's assume that $I_j(\epsilon)>0$, then, as the functions $S_k$ and $I_k$ are non negative, we have that $I_j(t)>0$ for $t>\epsilon$. If  we suppose that $I_j(\epsilon)=0$,
% by Taylor's theorem, we can see that
% \begin{equation*}
% \begin{split}
% I_j(t)&=I_j(\epsilon)+I_j'(\epsilon)(t-\epsilon)+h_{j,\epsilon}(t)\\
% &=I_j(\epsilon)+S_j(\epsilon)\sum_{k=1}^{n}\beta_{jk}I_k(\epsilon)(t-\epsilon)-\gamma I_j(\epsilon)(t-\epsilon)+h_{j,\epsilon}(t)\\
% &\geq I_j(\epsilon)+S_j(\epsilon)\beta_{ji}I_i(\epsilon)(t-\epsilon)-\gamma I_j(\epsilon)(t-\epsilon)+h_{j,\epsilon}(t)\\
% &=I_j(\epsilon)+N_j\beta_{ji}I_i(\epsilon)(t-\epsilon)+h_{j,\epsilon}(t).
% \end{split}
% \end{equation*}
% Thus
% \begin{equation*}
% \frac{I_j(t)-I_j(\epsilon)}{t-\epsilon}\geq N_j\beta_{ji}I_i(\epsilon)+\frac{h_{j,\epsilon}(t)}{t-\epsilon},
% \end{equation*}
% and therefore $I'_j(\epsilon)\geq N_j\beta_{ji}I_i(\epsilon)>0$, which implies that there exists $\epsilon_1>\epsilon$  such that if $t\in (\epsilon,\epsilon_1]$ then $I_j(t)>0$. Now,  reasoning analogously as we did for the case where $I_j(\epsilon)>0$, as  $I_j\left(\epsilon_1\right)>0$ then $I_j(t)>0$ for every $t>\epsilon_1$. Thus, $I_j(t)>0$ for all $t>\epsilon$. Since $\epsilon$ is an arbitrary positive number we have that $I_j(t)>0$ for every $t>0$.

% Suppose now that $\beta_{ij}=0$. 
% Since the matrix $\beta$ is irreducible, we have that there exist $j_1,j_2,\ldots,j_l \in \{1,2,\ldots,n\}$ such that $\beta_{{j_{1} i}}>0$, $\beta_{j_{r}j_{r-1}}>0$ for $r=2,3,\ldots,l$, and $\beta_{jj_{l}}>0$. Reasoning in the same way as we did in the previous paragraph we can see that, $I_{j_1}(t)>0$ for all $t>0$, which implies that $I_{j_2}(t)>0$ for every $t>0$ (note that is no neccesary that $I_{j_1}(0)>0$ to guarantee this fact), this last statement assure us that $I_{j_2}(0)>0$, and continuing in this way we can see that $I_j(t)>0$ for all $t>0$.




\end{proof}


\subsection{The number of vaccines  for  $t\to +\infty$}

The goal of this section is to show that, in some sense, the total number of vaccinated individuals $u_iS_i$ for any $i$ approaches zero as $t\to+\infty$. This regardless of the vaccination campaign. A very aggressive campaign, so that the vaccination rate $u_i$ are high, will imply that the number of susceptible individuals converges to zero fast enough so that the total number of vaccinated $u_iS_i$ also tends to zero.

What we have actually shown is that certain regularizations of the functions $u_iS_i$ converge to zero at infinity. To state the result that we want to present, let us recall the concept of \emph{regularization} or \emph{approximation of identity}  \cite{EliasM.Stein120}. Let $\varphi$ be an  integrable function on $\mathbb{R}$ satisfying $\int_\mathbb{R}\varphi(t)dt=1$.  In this article we will only consider functions $\varphi$  with $\varphi(t)=0$ when $t\leq 0$ and $\varphi$ decreasing on $[0,+\infty)$. For $\gamma>0$, we set $\varphi_\gamma(t)=\gamma\varphi(\gamma t)$ and for any $f\in L^1(\mathbb{R})$ with $f(t)\equiv 0$ for $t<0$, we write
\[
 f_{\gamma}(t)=f\ast \varphi_\gamma (t):= \gamma\int_{-\infty}^\infty f(t-s)\varphi(\gamma s)ds= \gamma\int_0^t f(t-s)\varphi(\gamma s)ds. 
\]

Then it is well known \cite{EliasM.Stein120} that $f_\gamma$ are continuous and  $f_\gamma\to f$  almost everywhere and in $L^p$-norm.  

 Suppose that $f\in L^\infty(\mathbb{R})$ and that there exists  $\lim_{t\to\infty}f(t)$.   Then, using the Lebesgue's dominated converge theorem 

 \begin{equation}\label{eq:lim-weak}
 \lim_{t\to\infty}f_\gamma(t) =\lim_{t\to\infty}f(t).
\end{equation}


\begin{comentario} Of course, the existence of the limit on the left hand side in equation \eqref{eq:lim-weak}   does not guarantee the existence of limit of $f(t)$ for $t\to\infty$. An example of this fact is shown uin appendix ?????.
\end{comentario}

The following proposition to expresses the fact that in the case when there are no demographic changes ($\mu=0$) and reinfections ($\alpha=0$) the  epidemic is extinguished when $t\to\infty$ and, in certain sense, the total quantity of applied vaccines $ u_iS_i$ goes to zero when $t\to\infty$.   

\begin{prop} We assume that $\mu=\alpha=0$ and  that $\varphi(t)=e^{-t}$, when $t>0$ and $\varphi(t)=0$ otherwise. The regularized function $(u_iS_i)_\gamma$ of the total number of appiled vaccines per unit of time goes to zero when $t\to\infty$. More concretely
\[
 \lim\limits_{t\to\infty}\gamma\int_0^t  u_i(s)S_i(s)
  e^{\gamma (s-t)}ds=I_i(\infty)=0.
\]

 
\end{prop}

\begin{proof} Adding equations \eqref{eq:ModeloSIRb1} and \eqref{eq:ModeloSIRb2} we obtain 
\[
 (S_i+I_i)'=- u_iS_i-\gamma I_i\leq 0.
\]
Therefore  $S_i+I_i$ is a monotone non increasing function. Hence $\lim_{t\to\infty} (S_i+I_i)$ there exists. From \eqref{eq:ModeloSIRb1} the same considerations are true for function $S_i$. Consequently there exists $\lim_{t\to\infty} S_i(t)=:S_i(\infty)$. We deduce that there exists  $\lim_{t\to\infty} I_i(t)=:I_i(\infty)$. If $I(\infty)>0$, we could choose $t_0$ large enough for that $t\geq t_0$ implies $I_i(t)>I_i(\infty)/2=:a>0$. Then $(S_i(t)+I_i(t))'\leq -\gamma I_i(t)\leq -\gamma a$. This inequality implies that $S_i(t) +I_i(t)\to -\infty$, when $t\to\infty$, which is a contradiction. Consequently $I_i(\infty)=0$. 

 
From  \eqref{eq:eq_integralI} we obtain 


\[
\begin{split}
 I_i(t)&=e^{-\gamma t}
 \left\{
    I_i(0)+\int_0^t e^{\gamma s} S_{i}(s) \Theta_i(s)ds
\right\}\\
&= e^{-\gamma t}
 \left\{
    I_i(0)-\int_0^t e^{\gamma s} \left[S'_i(s)+ u_i(s)S_i\right]ds 
  \right\}\\
  &= e^{-\gamma t}
 \left\{
    I_i(0)-\int_0^t e^{\gamma s}   u_i(s)S_i(s)ds
    -e^{\gamma t}S_i(t)+S_i(0)-\gamma\int_0^t e^{\gamma s} S_{i}(s) ds 
  \right\}\\
   &= e^{-\gamma t}\left(S_i(0)+ I_i(0)  \right)-S_i(t)
   +\gamma \int_0^t e^{\gamma (s-t)}S_{i}(s)ds-\int_0^t e^{\gamma (s-t)}   u_i(s)S_i(s)ds
 \end{split}
\]

The proof is completed by taking limit for $t\to\infty$ in previous identities and using \eqref{eq:lim-weak}. 
\end{proof}


\begin{conj} 
 \[
 \lim\limits_{t\to\infty}  u_i(s)S_i(s)
=0.
\]

\end{conj}


\section{Optimal control problem}


We suppose $T>0$ a fixed time and that $ M:[0,T]\to\mathbb{R}_+$ certain given \textcolor{blue}{bounded} non-negative function. We consider the admissible control set
\[\mathscr{U}=\left\{\bold{u}=\left( u_{1}, \ldots,  u_{n}\right):  u_{i}\right.\text{ measurable }, \left. u_{i} \geqslant 0,  u_{1}S_{1}+\cdots+ u_{n}S_{n}\leq M(t)\right\}.\]
Here, $ M(t)$ represent the number of vaccines per unit of time for the total population.


The objective function given by
\[ J(\bold{u})=\int_{0}^{T} \sum_{i=1}^{n} I_{i}(t) d t\]
we formulate the optimal control problem 
\begin{equation}\label{OptimalProblem}
\text{find}\quad  \bold{u}^{*} \in \mathscr{U} \quad \text{such that}\quad 
          J\left(\bold{u}^{*}\right)=\min _{\bold{u}\in  \mathscr{U}} J(\bold{u}).
\end{equation}



\section{Existence minimizers}

In this Section, we prove that the optimal control problem (\ref{OptimalProblem}) has a solution. That is, we prove that the hypothesis of the Filippov-Cesari Theorem are satisfied (see \cite{A.Seierstad499}). In what follows, we will use the following notation:
\[f_{0}\left(\bold{x}, \bold{u}, t\right)=f_{0}\left(S_{1}, \ldots, S_{n}, I_{1}\ldots, I_n;  u_{1}, \ldots,  u_{n} ; t\right)\]
where
$$
\bold{x}=\left(S_{1}, \ldots, S_{n}, I_{1}, \ldots, I_{n}\right) \quad \text{and}\quad \bold{u}=\left(u_{1}, \ldots,  u_{n}\right).
$$
We denote by $f=\left(f_{1}, \ldots, f_{n}\right)$ and 
$$
f_{i}=\left(f_{1 i}, f_{2 i}\right)  \quad \text{for} \quad i=1,2,\cdots, n
$$
with
\[
f_{1 i}=(\mu+\alpha) N_i-S_{i}(t)\left[ \sum\limits_{j=1}^{n} \beta_{i j} I_{j}(t)+ u_{i}(t) +\mu+\alpha\right] -\alpha I_i(t)
\]
\[f_{2i}=S_{i}(t) \sum\limits_{j=1}^{n} \beta_{i j} I_{j}(t)-(\mu+\gamma) I_{i}(t).
\]
Taking into account that, in this case, we consider 
$$
f_{0}\left(\bold{x}, \bold{u}, t\right)=\sum_{i=1}^{n} I_{i}(t)
$$
we define
$$N\left(\bold{x}, \mathscr{U}, t\right)=\left\{\left(f_{0}+\gamma, f\right):\, \gamma \geq 0,\,  \bold{u} \in \mathscr{U}\right\}$$
and we will prove the following result.

\todo{Demostrar el teorema de existencia para $n$ nodos y con reinfecciones
y demografía} 

\begin{thm}
The optimal control problem (\ref{OptimalProblem}) has a solution $\bold{u}^{*} \in \mathscr{U}$.
\end{thm}
\begin{proof}
We will prove that $N(\bold{x}, \mathscr{U}, t)$ is a convex set, for all $(\bold{x},t)$. In fact, let 
$\left(a_{1}, \bold{b}_{1}\right), \left(a_{2}, \bold{b}_{2}\right) \in N\left(\bold{x}, \mathscr{U}, t\right)$ be, then there exist $\gamma_{1}, \gamma_{2} \geq 0$ and $\bold{u}_{1}, \bold{u}_2 \in  \mathscr{U}$ such that 
$$
\left(f_{0}\left(\bold{x}, \bold{u}_{1}, t\right)+\gamma_{1} ; f\left(\bold{x}, \bold{u}_{1}, t\right)\right)=\left(a_{1}, \bold{b}_{1}\right) 
$$
and
$$
\left(f_{0}\left(\bold{x}, \bold{u}_{2}, t\right)+\gamma_{2}, f\left(\bold{x}, \bold{u}_{2}, t\right)\right)=\left(a_{2}, \bold{b}_{2}\right)
$$
then 
$$
\lambda\left(a_{1}, \bold{b}_{1}\right)+(1-\lambda)\left(a_{2}, \bold{b}_{2}\right)=\left(\lambda a_1+(1-\lambda) a_{2}, \lambda \bold{b}_{1}+(1-\lambda) \bold{b}_{2}\right)
$$
$$
=\left(\lambda\left(f_{0}\left(\bold{x}, \bold{u}_{1}, t\right)+\gamma_{1}\right)+(1-\lambda)\left(f_{0}\left(\bold{x}, \bold{u}_{2}, t\right)+\gamma_{2}\right), \lambda f\left(\bold{x}, \bold{u}_{1}, t\right)+(1-\lambda) f\left(\bold{x}, \bold{u}_{2}, t\right)\right).
$$
Now, we consider the second component
$$
\lambda f\left(\bold{x}, \bold{u}_{1}, t\right)+(1-\lambda) f\left(\bold{x}, \bold{u}_{2}, t\right)
$$
and from the linearity of $f$ with respect to $\bold{u}$, we have 
\[\lambda f\left(\bold{x}, \bold{u}_{1}, t\right)+(1-\lambda) f\left(\bold{x}, \bold{u}_{2}, t\right)=f\left(\bold{x}, \lambda  \bold{u}_{1}+(1-\lambda) \bold{u}_{2}, t\right).\]
Moreover, if $\bold{u}_1,\bold{u}_2\in \mathscr{U}$ then $\overline{u}=\lambda  \bold{u}_{1}+(1-\lambda) \bold{u}_{2} \in \mathscr{U}$. In fact, $\lambda \bold{u}_{1}+(1-\lambda) \bold{u}_{2}$ is measurable. If we denote by $ \bold{u}_{1}=\left( u_{11}, \ldots ,  u_{1 n}\right)$ and $ \bold{u}_{2}=\left( u_{21}, \ldots , u_{2 n}\right)$, we have that $\lambda  u_{1i}+(1-\lambda) u_{2i} \geqslant 0$, $\forall i=1, ...,n$. Next, \[
\lambda \bold{u}_{1}+(1-\lambda)  \bold{u}_{2}=\left(\lambda  u_{11}+(1-\lambda)  u_{21}, \ldots,\lambda  u_{1 n}+(1-\lambda)  u_{2 n}\right)
\]
then, for each fixed $t\in [0,T]$, we have
$$
\begin{array}{l}
\left(\lambda  u_{11}+(1-\lambda)  u_{21}\right)S_{1}+\cdots+\left(\lambda  u_{1n}+(1-\lambda)  u_{2n}\right)S_{n}=\\
\lambda\left( u_{11}S_{1}+\cdots+ u_{1 n}S_{n}\right)+(1-\lambda)\left( u_{21}S_{1}+\cdots+ u_{2 n}S_{n}\right)\leq M(t)
\end{array}
$$
therefore $\overline{u}=\lambda \bold{u}_{1}+(1-\lambda) \bold{u}_{2}\in \mathscr{U}$.
\newline
Now, we will prove that there exists $\gamma \geq 0$ such that
$$f_{0}\left(x, \overline{ u}, t\right)+\gamma=\lambda a_{1}+(1-\lambda) a_{2}.$$
We note that $f_0$ is constant with respect to the control variable, then
$$
f_{0}\left(\bold{x}, \lambda \bold{u}_{1}+(1-\lambda) \bold{u}_{2}, t\right)=\lambda f_{0}\left(\bold{x}, \bold{u}_{1}, t\right)+(1-\lambda) f_{0}\left(\bold{x}, \bold{u}_{2}, t\right).
$$
If we define $\gamma=\lambda \gamma_{1}+(1-\lambda) \gamma_{2} \geq 0$, we have that
$$
\begin{aligned}
f_{0}\left(\bold{x},\lambda \bold{u}_{1}+(1-\lambda) \bold{u}_{2}, t\right)+\gamma &=\left[\lambda f_{0}\left(\bold{x},\bold{u}_{1}, t\right)+(1-\lambda) f_{0}\left(\bold{x}, \bold{u}_{2}, t\right)\right]\\ &\quad +\left[(\lambda \gamma_{1}+(1-\lambda) \gamma_{2}\right] \\
&=\lambda f_{0}\left(\bold{x},\bold{u}_{1}, t\right)+\lambda \gamma_{1}+(1-\lambda) f_{0}\left(\bold{x}, \bold{u}_{2}, t\right)\\ &\quad +(1-\lambda) \gamma_{2} \\
&=\lambda\left(f_{0}\left(\bold{x},  u_{1}, t\right)+\gamma_{1}\right)+(1-\lambda)\left(f_{0}\left(\bold{x}, \bold{u}_{2}, t\right)+\gamma_{2}\right) \\
&=\lambda a_{1}+(1-\lambda) a_{2}.
\end{aligned}
$$
Therefore, we proved that there exists 
$\gamma=\lambda \gamma_{1}+(1-\lambda) \gamma_{2} \geq 0$ and there exists $\overline{ u}=\lambda \bold{u}_{1}+(1-\lambda) \bold{u}_{2} \in \mathscr{U}$
such that 
$$\left(\lambda {a_{1}}+(1-\lambda) {a_{2}}, \lambda \bold{b}_{1}+(1-\lambda) \bold{b}_{2}\right)=\left(f_{0}\left(\bold{x}, \overline{ u}, t\right)+\gamma , f\left(\bold{x}, \overline{ u}, t\right)\right)$$
i.e.
$$\left(\lambda a_{1}+(1-\lambda) a_{2}, \lambda \bold{b}_{1}+(1-\lambda) \bold{b}_{2}\right) \in N\left(\bold{x}, \mathscr{U}, t\right)$$
and $N\left(\bold{x}, \mathscr{U}, t\right)$ is a convex set, for all fixed $(\bold{x},t)$.
\newline
The set $\mathscr{U}$ is compact, since for all $\bold{u}= \left( u_{1}, \ldots,  u_{n}\right)\in \mathscr{U}$ and fixed $t\in [0,T]$, we have that
$$0 \leq  u_{1}S_1+\ldots+ u_{n}S_n \leq M(t).$$ 
Finally, taking into account that the number of susceptible, infected and removed individuals are bounded by the total quantity of individuals, we have that there exists a positive constant $c$ such that $\|\bold{x}(t)\| \leqslant c$, where $\|\cdot\|$ represent a norm in $\mathbb{R}^{n}$. Therefore, we have verified the hypothesis of Filippov-Cesari Existence Theorem and the thesis holds.
\end{proof}

\section{Necessary conditions}

In this Section, we apply the Pontryagin Maximum Principle \cite[Th. 4.1]{A.Seierstad499}, \cite{hartl1995survey} for to  obtain necessary conditions  in order to $(\bm{x}^*,\bm{u}^*)=(\bm{S}^*,\bm{I}^*,\bm{u}^*)$ be a solution of the optimal problem 


\begin{subequations}
\makeatletter
\def\@currentlabel{OP}
\makeatother
\label{eq:optimal_model}
\renewcommand{\theequation}{OP${}_\arabic{equation}$}
\begin{empheq}[left=\empheqlbrace]{align}
              &\min _{ u} \int_{0}^{T} \sum_{i=1}^{n} I_{i}(t) d t \\
\text{s. t. } & \notag \\ 
                & \bm{S}'=\bm{f}_{\bm{S}}(\bm{S},\bm{I},\bm{u})=\nu\bm{N}-\bm{S}\times (\bm{\beta}\bm{I}+\bm{u})-\nu\bm{S}-\alpha\bm{I}\\
                &\bm{I}'=\bm{f}_{\bm{I}}(\bm{S},\bm{I},\bm{u})=\bm{S}\times \bm{\beta}\bm{I}-(\mu+\gamma)\bm{I}.\\
                & \bm{S}(0)=\bm{S}_0,\quad \bm{I}(0)=\bm{I}_0\\
                & \bm{S}(T),\quad \bm{I}(T),\quad\text{free}\notag\\
                & \bm{u}\cdot \bm{S}\leq M(t)\\
                & \bm{u}\geq 0 
\end{empheq} 
\end{subequations}
As is well known the maximun principle involves the Hamiltonian formulation of the optimal problem. We consider \emph{adjoint variables}, $\bm{p}_S(t)=(p_{S1}(t),\ldots,p_{Sn}(t))$ and $\bm{p}_I(t)=(p_{I1}(t),\ldots,p_{In}(t))$ and the Hamiltonian function defined by
\begin{empheq}{multline}\label{eq:hamiltoniano}
\mathscr{H}(\bm{S},\bm{I},\bm{u},\bm{p}_S,\bm{p}_I)=
-p_0 \sum_{i=1}^{n} I_{i}  
 +\bm{p}_{S}\cdot \bm{f}_{\bm{S}}(\bm{S},\bm{I},\bm{u})+ \bm{p}_I\cdot \bm{f}_{\bm{I}}(\bm{S},\bm{I},\bm{u}),
\end{empheq} 
where $p_0\in\mathbb{R}$ is independent of $t$. It is necessary to introduce  new multipliers $q_0(t)$ and $\bm{q}(t)=(q_1(t),\ldots,q_n(t))$ associated with each constraint and the  \emph{Lagrangian} or \emph{generalized Hamiltonian} $\mathscr{L}$ defined by
\begin{empheq}{equation}\label{eq:lagrangiano_generalizado}
\mathscr{L}(\bm{S},\bm{I},\bm{u},\bm{p}_S,\bm{p}_I,\bm{q})=\mathscr{H}(\bm{S},\bm{I},\bm{u},\bm{p}_S,\bm{p}_I)+\bm{q}\cdot \bm{u}-q_0 \bm{u}\cdot \bm{S}.
\end{empheq} 

We suppose that $(\bm{S}^*,\bm{I}^{*},  \bm{u}^{*})$ is a  solution of \eqref{eq:optimal_model}. From now on any function evaluated at  $(\bm{S}^*,\bm{I}^{*},  \bm{u}^{*})$  will be indicated with a $\ast$ as superscript.

We combine the restrictions in a vector valued function 
$$\bm{h}(\bm{S},\bm{u},t)=(\bm{u}_1,\ldots, \bm{u}_n,-\bm{u}\cdot \bm{S}+M(t)).$$
Then, the constraints are expressed synthetically $\bm{h}\geq \bm{0}$, where order relations between vectors mean that these relations are given component by component. Following  to be able to apply the Maximum Principle  it is necessary that they satisfy the  
According to \cite[Th. 4.1]{A.Seierstad499}, see also \cite{hartl1995survey}, in order to apply the maximum principle, the  constraint
qualification condition must be satisfied. This condition  means that the gradients of the active constraints ( this is $ \{i :h_i=0\}$) are linearly. In our case, the following condition must be satisfied

\begin{equation}\label{eq:cons_qua}
n+1=
 \operatorname{rank}
                    \left[
                    \begin{array}{c c c|c c c c }
                      1      & \cdots & 0      & u_1    & \cdots& 0 &  0       \\
                      \vdots & \ddots & \vdots & \vdots & \ddots&\vdots & \vdots   \\
                      0      & \cdots & 1      & 0 &\cdots &  u_n   &   0      \\                                  
                      -S_1   &\cdots  & -S_n      & 0      &\cdots &0 & -\bm{u}\cdot \bm{S}+M(t)\\
                     \end{array}
                    \right]
\end{equation}
We note that if $-\bm{u}\cdot \bm{S}+M(t)\neq 0$ then then qualification condition follows inmediately. In the case that   $-\bm{u}\cdot \bm{S}+M(t)= 0$ (last constraint active) we can  prove  that  the matrix en the rhs of  \eqref{eq:cons_qua} can be row reduced to
\begin{equation*}\label{eq:cons_qua}
                    \left[
                    \begin{array}{c c c|c c c c }
                      1      & \cdots & 0      & u_1    & \cdots& 0 &  0       \\
                      \vdots & \ddots & \vdots & \vdots & \ddots&\vdots & \vdots   \\
                      0      & \cdots & 1      & 0 &\cdots &  u_n   &   0      \\                                  
                      0   &\cdots  & 0      & u_1S_1      &\cdots & u_nS_n & 0\\
                     \end{array}
                    \right].
\end{equation*}
Since $-\bm{u}\cdot \bm{S}+M(t)= 0$, there is some $i$ with $u_iS_i\neq 0$. This implies that matrix has completed rank. 

We are in a position to apply the maximum principle. First we observe 
that in virtue of  equations (29), 
(34) and (35c) in \cite[Th. 4.1]{A.Seierstad499} we can assume  that 
$p_0=1$ in \eqref{eq:hamiltoniano}. On the other hand, we infer that 
there exist
functions $ \bm{p}^\ast_S,\bm{p}^\ast_I:[0,T]\to\mathbb{R}^n$
 and 
\emph{multipliers} $\bm{q}=(q_0(t),\ldots,q_n(t))\in\mathbb{R}^{n+1}$ 
such that  the following 
conditions are satisfied

\noindent 1.\emph{ Adjoint equations}
 
 \begin{subequations}
\makeatletter
\def\@currentlabel{ADJ}
\makeatother
\label{eq:estado_adj}
\renewcommand{\theequation}{ADJ${}_\arabic{equation}$}
\begin{empheq}[left=\empheqlbrace]{alignat=3}
\dot{\bm{p}}_{\bm{S}} 
    &=-\frac{\partial \mathscr{L}^\ast}{\partial \bm{S}}
        &={\bm{p}}_{\bm{S}} \times \left(\bm{\beta} \bm{I}^\ast +\bm{u}^\ast+\nu\right) 
            -{\bm{p}}_{\bm{I}}\times  \bm{\beta} \bm{I}+q_0\bm{u}^\ast,\label{eq:cons_adjS}\\
\dot{\bm{p}}_{\bm{I}} 
    &=-\frac{\partial \mathscr{L}^\ast}{\partial \bm{I}}
        &= p_0\bm{1}+ \bm{\beta}^t\left( \bm{S}^\ast\times \left( {\bm{p}}_{\bm{S}}-  
            {\bm{p}}_{\bm{I}} \right)\right)
                +\alpha {\bm{p}}_{\bm{S}}+(\mu+\gamma) {\bm{p}}_{\bm{I}},\label{eq:cons_adjI}
\end{empheq}
\end{subequations}
where $\bm{1}=(1,\ldots,1)\in\mathbb{R}^n$.
 

\noindent 2.\emph{ }
 \begin{empheq}{equation}\label{eq:L_critico}
  0=\frac{\partial \mathscr{L}^\ast}{\partial \bm{u}}=
  -{\bm{p}}_{\bm{S}}\times \bm{S}^\ast +\bm{q}-q_0\bm{S}^\ast
 \end{empheq}

\noindent 3.\emph{ Positivity and complementary slackness conditions } 
 \begin{empheq}{equation}\label{eq:rest-act}
  \bm{q}(t)\geq 0 \quad \text{ and }\quad  \bm{q}(t)\cdot 
  \bm{h}(\bm{S}^\ast,\bm{u}^\ast, t)=0
 \end{empheq}

\noindent 4.\emph{ Terminal condition }  

 \begin{empheq}{equation}\label{eq:p-values}
  p_0=1 \quad \text{ and }\quad  \bm{p}_{\bm{S}}(T)= \bm{p}_{\bm{I}}(T)=0.
 \end{empheq}


\noindent 5.\emph{ Maximality. } For fix $t\in[0,T]$ and for 
every $\bm{u}$ with  $\bm{h}(\bm{S}^\ast,\bm{u},t)\geq \bm{0}$ we have
\begin{empheq}{align}\label{eq:maximalidad}
\mathscr{H}(\bm{S}^\ast,\bm{I}^\ast,\bm{u}^\ast,\bm{p}_S,\bm{p}_I)\geq 
\mathscr{H}(\bm{S}^\ast,\bm{I}^\ast,\bm{u},\bm{p}_S,\bm{p}_I)
\end{empheq}




\begin{cor} We suppose that $(\bm{S}^*,\bm{I}^{*},  \bm{u}^{*})$ is a  solution of \eqref{eq:optimal_model}.  Let $F(t)\subset \{1,\ldots,n\}$  be the subset of indices defined by 
$$j\in F(t) \Longleftrightarrow \bm{p}_{\bm{S}^\ast j}(t) = p_{\text{min}}(t):=
\min\{\bm{p}_{\bm{S}^\ast 1}(t),\ldots, \bm{p}_{\bm{S}^\ast n}(t)\}.$$
Then 
\begin{equation}\label{eq:cond_cont}
     u^\ast_k(t)=0,\quad\text{for every } k\notin F(t).
\end{equation}
\end{cor}
\begin{proof}
 
We observe that the Hamiltonian can be written 

\begin{equation}\label{eq:hamiltonian_afin}
 \mathscr{H}(\bm{S},\bm{I},\bm{u},\bm{p}_S,\bm{p}_I)= \mathscr{H}_0(\bm{S},\bm{I},\bm{p}_S,\bm{p}_I)-
 \bm{p}_{\bm{S}}\cdot (\bm{S}\times \bm{u}).
\end{equation}
Therefore  \eqref{eq:hamiltonian_afin} implies that for each $t\in[0,T]$ and for every $\bm{u}$ with  $\bm{u}\geq \bm{0}$ and $\bm{u}\cdot\bm{S}^\ast\leq M(t)$ we have
\begin{equation}\label{eq:maximalidad2}
  \bm{p}_{\bm{S}}\cdot (\bm{S}^\ast\times \bm{u}^\ast)\leq  \bm{p}_{\bm{S}}\cdot (\bm{S}^\ast\times \bm{u})
\end{equation}
Therefore for every $\bm{u}$ with  $\bm{u}\geq \bm{0}$ and $\bm{u}\cdot\bm{S}^\ast\leq M(t)$
\[
 \bm{p}_{\bm{S}}\cdot (\bm{S}^\ast\times \bm{u})\geq p_{\text{min}}(t) M
\]


Suppose that there exists $k\notin F(t)$ such that $u_k^ \ast>0$

\end{proof}








\section{Numerical results}  

..........................


\section{appendix}



\[
 h=\sum_{n=0}^{\infty}\mathbbm{1}_{[n,n+\frac12]},
\]
where $\mathbbm{1}_{A}$ denotes the characteristic function of the set $A$.  Then $h(s)+h(s-\frac12)=1$, for $s\in [0,+\infty]$. 
We define $\varphi(s)=h(e^s-1)$. Then
\begin{multline}\label{eq:sum_1}
 1=\lim\limits_{t\to\infty}\gamma\int_0^t \left(\varphi(s)+\varphi\left(s-\frac12\right)
 \right) e^{\gamma (s-t)}ds\\=\lim\limits_{t\to\infty}\gamma\int_0^t\varphi(s)e^{\gamma (s-t)}ds+ \gamma\int_0^t \varphi\left(s-\frac12\right)
  e^{\gamma (s-t)}ds
\end{multline}
On the other hand
\begin{multline}\label{eq:tras_12}
 \gamma\int_0^t \varphi\left(s-\frac12\right)
  e^{\gamma (s-t)}ds= \gamma e^{\frac{\gamma}{2}}\int_0^{t-\frac12} \varphi\left(r\right)
  e^{\gamma (r-t)}dr\\=\gamma e^{\frac{\gamma}{2}}\int_0^{t} \varphi\left(r\right)
  e^{\gamma (r-t)}dr-
  \gamma e^{\frac{\gamma}{2}}\int_{t-\frac12}^{t} \varphi\left(r\right)
  e^{\gamma (r-t)}dr
\end{multline}

In my understanding
\[
\lim\limits_{t\to\infty} \int_{t-\frac12}^{t} \varphi\left(r\right)
  e^{\gamma (r-t)}dr= \frac{1}{2\gamma}(1-e^{-\gamma/2}).
\]

Taking account of \eqref{eq:sum_1}, \eqref{eq:tras_12} we infer that 
\[
\lim\limits_{t\to\infty} \gamma \int_{0}^{t} \varphi\left(s\right)
  e^{\gamma (s-t)}ds=\frac{e^{\gamma/2}}{2(1+e^{\gamma/2})}
\]


  \bibliographystyle{plain}
  \bibliography{control, epidemias, EpidemiologiaPapers,otros}

\end{document}
