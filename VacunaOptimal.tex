\documentclass[a4paper,10pt]{article}
\usepackage[utf8]{inputenc}
\usepackage{amsmath, amsthm, amssymb}
\usepackage{color}
\usepackage{systeme}
\usepackage[utf8]{inputenc}
\usepackage{empheq}
\usepackage{bbm}
 
\newtheorem{thm}{Theorem}[section]
\newtheorem{cor}[thm]{Corollary}
\newtheorem{lem}[thm]{Lemma}
\newtheorem{rem}[thm]{Remark}
\newtheorem{exa}[thm]{Example}
\newtheorem{defn}[thm]{Definition}
\newtheorem{conj}[thm]{Conjecture}
\newtheorem{prop}[thm]{Proposition}
\theoremstyle{remark}
\newtheorem{comentario}{Remark}

%opening
\title{Optimal control on a vaccine metapopulation SIR model}
\author{
}



\begin{document}

\maketitle

\begin{abstract}

\end{abstract}


\section{Introduction}




We consider the following SIR model of metapopulations with migrations:
\begin{equation}\label{eq:ModeloSIR}
\left\{\begin{array}{l}\frac{d S_{i}}{d t}=\mu N_{i}-S_{i}(t) \sum_{j=1}^{n} \beta_{i j} I_{j}(t)-\delta \sigma_{i} S_{i}(t)-d S_{i}(t) \\ 
\frac{d I_{i}}{d t}=S_{i}(t) \sum_{j=1}^{n} \beta_{i j} I_{j}(t)-(d+\alpha+\gamma) I_{i}(t) \\ 
\frac{d R_{i}}{d t}=\gamma I_{i}(t)+\delta \sigma_{i} S_{i}(t)-d R_{i}(t)\\
S(0)=S_{i 0};\quad I_{i}(0)=I_{i 0};\quad R_{i}(0)=R_{i 0}
\end{array}\right. 
\end{equation}
where 
\begin{itemize}
\item $\beta_{ij}$ is the transmission rate per capita per time unit of individuals of the class $i$ with the class $j$.
\item $\mu$ is the birth rate. 
\item $\sigma_{i}$ is the vaccination rate at the node $i$ (control variable).
\item $\gamma$ is the recovery rate. 
\item $d$ is the natural death rate. 
\item $\alpha$ is the death rate from the disease (case fatality). 
\item $\delta$ is the vaccine effectiveness.
\end{itemize}

\def\svgwidth{9cm}
\input{SIR_vacuna.pdf_tex}

We suupose that $\sigma_{T}:[0,T]\to\mathbb{R}_+$ is a non-negative function. We consider the admissible control set
\[U_{ad}=\left\{\sigma=\left(\sigma_{1}, \ldots, \sigma_{n}\right): \sigma_{i}\right.\text{ measurable }, \left.\sigma_{i} \geqslant 0, \sigma_{1}S_{1}+\cdots+\sigma_{n}S_{n}\leq\sigma_{T}(t)\right\}.\]
Here, $\sigma_{T}(t)$ represent the number of vaccines per unit of time for the total population.


\begin{color}{red} Nota 26/07/2022: 

$\sigma_i = $\# Vacunados nodo  $i$ $\times $ unidad de tiempo $\times $ suceptible del nodo $i$. 

La cantidad total de vacunas suministradas en el nodo $i$ es $\sigma_iS_i$. Estamos considerando igual de admisibles distribuciones de vacunas que en total pueden resultar en cantidades de vacunados muy diferentes. Parece m치s razonable que el conjunto admisible sea algo del tipo:
\[ \sigma_{1}S_1+\cdots+\sigma_{n}S_n\leq \sigma_{T}(t)\]

Ahora $\sigma_T(t)$ representan cantidad de vacunas por unidad de tiempo en la poblaci칩n total. Quiz치s que la cantidad de vacunados no se exprese como $\sigma_i S_i$. Discutir un poco esto.

\end{color}

The objective function given by
\[ J(\sigma)=\int_{0}^{T} \sum_{i=1}^{n} I_{i}(t) d t\]
we formulate the optimal control problem 
\begin{equation}\label{OptimalProblem}
\text{find}\quad \sigma^{*} \in U_{a d} \quad \text{such that}\quad 
          J\left(\sigma^{*}\right)=\min _{\sigma\in  U_{a d}} J(\sigma)
\end{equation}

\section{Some observations on dynamics of vaccine metapopulation model}

\begin{prop} Let $S_i$, $I_i$ and $R_i$, $i=1,2,\ldots,n$ be the solutions of \eqref{eq:ModeloSIR}. If $S_{i0}\geq 0$, $I_{i0}\geq 0$ and $R_{i0}\geq 0$ for every $i=1,2,\ldots,n$ then $S_{i}(t)\geq 0$, $I_{i}(t)\geq 0$ and $R_{i}(t)\geq 0$ for  $i\in\{1,2,\ldots,n\}$ and  $t>0$.
\end{prop}

\begin{proof}
Let $C_1=\left\{(X,Y,Z)\in\mathbb{R}^{3n}: X_i\geq 0, Y_i\geq 0, Z_i\geq 0,\ \text{for}\ i=1,2,\ldots,n \right\}$. Let's define the function $f:\mathbb{R}^{3n}\times [0,\infty)\to \mathbb{R}^{3n}$ as
\begin{equation*}
    f(X,Y,Z,t)=\left(\begin{array}{l}\mu N_{i}-X_{i} \sum_{j=1}^{n} \beta_{i j} Y_{j}-\delta \sigma_{i}(t) X_{i}-d X_{i} \\ 
X_{i} \sum_{j=1}^{n} \beta_{i j} Y_{j}-(d+\alpha+\gamma) Y_{i} \\ 
\gamma Y_{i}+\delta \sigma_{i}(t) X_{i}-d Z_{i}
\end{array}\right)
\end{equation*}
To demosntrate this Proposition, By Theorem ??????, we only need to prove that for every $(X,Y,Z)\in C_1$ and $t\in [0,\infty)$, the equality
\begin{equation}\label{eq:lim=0}
    \lim\limits_{h\to 0^{+}}\frac{\textrm{d}\left( (X,Y,Z)+hf(X,Y,Z,t),C_1\right)}{h}=0
\end{equation}
 is satisfied, here $\textrm{d}$ represents the Euclidean distance in $\mathbb{R}^{3n}$. Let $\tilde{\delta}>0$ such that 
 \begin{equation*}
     \tilde{\delta}\left(\sum_{j=1}^n\beta_{ij}Y_{j}+\delta\sigma_{i}(t)+d\right)<1, \ \ \ \tilde{\delta}\left(\beta_{ii}X_i+\delta+\gamma+\alpha\right)<1 \ \ \ \text{and} \ \ \ \tilde{\delta}d<1
 \end{equation*}
for every $i\in\{1,2,\ldots,n\}$. Now, if $0<h<\tilde{\delta}$ the expression $(X,Y,Z)+hf(X,Y,Z,t)\in C_1$ and therefore equation \eqref{eq:lim=0} holds.
\end{proof}

We assume $\mu=d=\alpha=0$ and $\delta=1$. In this situation $N_i':=(S_i+I_i+R_i)'=0$, i.e. the total population of node $i$ remain constant. Cosequently $R_i=N-S_i-I_i$ and  we can drop the equation for $R_i$  of the system. Therefore, we can study the SIR metapopulation model with vaccination (SIRmv) system.

  \begin{empheq}[left=\empheqlbrace]{align}
 S'_{i} &= -S_{i}(t) \sum\limits_{j=1}^{n} \beta_{i j} I_{j}(t)-  \sigma_{i}(t) S_{i}(t)\label{eq:SIRmv1}\tag{SIRmv1}\\
 I'_{i}&=S_{i}(t) \sum\limits_{j=1}^{n} \beta_{i j} I_{j}(t)-\gamma I_{i}(t)
 \label{eq:SIRmv2}\tag{SIRmv2}
  \end{empheq}

  
We  note that the system of equations \eqref{eq:SIRmv1}, \eqref{eq:SIRmv1} possibly has a discontinuous right hand side. I this case,  I this case, following to \cite{A.F.Filippov512}. \textcolor{red}{Poner el significado de soluci칩n}
  



We will use the following well known and elementary formula for the solution of a linear scalar eqution of first order $x'(t)+p(t)x(t)=q(t)$:
\begin{equation}\label{eq:1order}
 x(t)=e^{-\int_0^tp(s)ds}\left\{x(0)+\int_0^t e^{\int_0^sp(r)dr}q(s) ds \right\}
\end{equation}

From  \eqref{eq:SIRmv1} and \eqref{eq:1order} we obtain that

\[
 S_i(t)=S_i(0)
 \exp\left(
    -\int_0^t\sum\limits_{j=1}^{n} \beta_{i j} I_{j}(s)+\sigma(s)ds
    \right)
\]




The following conjecture establish that if is a irreducible matrix (see \cite{CarlD.Meyer538}) the epidemic is transmitted from any node to the rest with infinite speed.


\begin{prop} Suppose that $\beta$ is a irreducible matrix. If there exists $i$ such that $I_i(0)>0$ then for evey $j$ and $t>0$ we have $I_j(t)>0$.
\end{prop}
 
\begin{proof} Let $i,j\in \{1,2,\ldots,n\}$ such that $I_i(0)>0$ and $i \neq j$. 

Suppose first that $\beta_{ij}>0$. 
Let's fix $\epsilon>0$ and see that $I_j(t)$ is positive for all  $t>\epsilon$. As $I_i(0)>0$ then $I_i(\epsilon)>0$. For $t>\epsilon$ we have that
\begin{equation*}
I_j(t)=e^{-\int_{\epsilon}^{t}(\gamma-\beta_{jj}) ds}\left(I_j(\epsilon)+\int_{\epsilon}^{t}e^{\int_{\epsilon}^{s}(\gamma-\beta_{jj}) dz}\left[S_j(s)\sum_{k=1,k\neq j}^{n}\beta_{jk}I_k(s)\right]ds\right).
\end{equation*}
Let's assume that $I_j(\epsilon)>0$, then, as the functions $S_k$ and $I_k$ are non negative, we have that $I_j(t)>0$ for $t>\epsilon$. If  we suppose that $I_j(\epsilon)=0$,
by Taylor's theorem, we can see that
\begin{equation*}
\begin{split}
I_j(t)&=I_j(\epsilon)+I_j'(\epsilon)(t-\epsilon)+h_{j,\epsilon}(t)\\
&=I_j(\epsilon)+S_j(\epsilon)\sum_{k=1}^{n}\beta_{jk}I_k(\epsilon)(t-\epsilon)-\gamma I_j(\epsilon)(t-\epsilon)+h_{j,\epsilon}(t)\\
&\geq I_j(\epsilon)+S_j(\epsilon)\beta_{ji}I_i(\epsilon)(t-\epsilon)-\gamma I_j(\epsilon)(t-\epsilon)+h_{j,\epsilon}(t)\\
&=I_j(\epsilon)+N_j\beta_{ji}I_i(\epsilon)(t-\epsilon)+h_{j,\epsilon}(t).
\end{split}
\end{equation*}
Thus
\begin{equation*}
\frac{I_j(t)-I_j(\epsilon)}{t-\epsilon}\geq N_j\beta_{ji}I_i(\epsilon)+\frac{h_{j,\epsilon}(t)}{t-\epsilon},
\end{equation*}
and therefore $I'_j(\epsilon)\geq N_j\beta_{ji}I_i(\epsilon)>0$, which implies that there exists $\epsilon_1>\epsilon$  such that if $t\in (\epsilon,\epsilon_1]$ then $I_j(t)>0$. Now,  reasoning analogously as we did for the case where $I_j(\epsilon)>0$, as  $I_j\left(\epsilon_1\right)>0$ then $I_j(t)>0$ for every $t>\epsilon_1$. Thus, $I_j(t)>0$ for all $t>\epsilon$. Since $\epsilon$ is an arbitrary positive number we have that $I_j(t)>0$ for every $t>0$.

Suppose now that $\beta_{ij}=0$. 
Since the matrix $\beta$ is irreducible, we have that there exist $j_1,j_2,\ldots,j_l \in \{1,2,\ldots,n\}$ such that $\beta_{{j_{1} i}}>0$, $\beta_{j_{r}j_{r-1}}>0$ for $r=2,3,\ldots,l$, and $\beta_{jj_{l}}>0$. Reasoning in the same way as we did in the previous paragraph we can see that, $I_{j_1}(t)>0$ for all $t>0$, which implies that $I_{j_2}(t)>0$ for every $t>0$ (note that is no neccesary that $I_{j_1}(0)>0$ to guarantee this fact), this last statement assure us that $I_{j_2}(0)>0$, and continuing in this way we can see that $I_j(t)>0$ for all $t>0$.



\end{proof}

\begin{lem}\label{lem:lim-weak} Let $h\in L^{\infty}([0,+\infty))$ be a function. Suppose that there exists  $\lim_{t\to\infty}h(t)$ and denote it by $h_{\infty}$. Then
\begin{equation}\label{eq:lim-weak}
 h_{\infty}=\lim_{t\to\infty}\gamma\int_0^th(s)e^{\gamma (s-t)}ds.
\end{equation}
\end{lem}
\begin{proof} Given $\varepsilon>0$ there exists $t_0\geq 0$ such that 
\[
 t\geq t_0\Rightarrow |h(t)-h_{\infty}|<\varepsilon.
\]
Using the identity
\[
 \gamma\int_0^te^{\gamma (s-t)}ds=1-e^{-\gamma t},
\]
we can deduce

 \begin{multline*}
  \left|h_{\infty}-\gamma\int_0^th(s)e^{\gamma (s-t)}ds\right|=
  \left|e^{-\gamma t}h_{\infty}+ \gamma\int_0^t\left(h_{\infty}-h(s)\right)e^{\gamma (s-t)}ds \right|\\
  \leq e^{-\gamma t}|h_{\infty}|+  \gamma\int_0^{t_0} \left|h_{\infty}-h(s)\right| e^{\gamma (s-t)}ds +\gamma\int_{t_0}^{t} \left|h_{\infty}-h(s)\right| e^{\gamma (s-t)}ds\\
  e^{-\gamma t}|h_{\infty}|+2\gamma\|h\|_{L^{\infty}}e^{\gamma(t_0-t)}t_0+\varepsilon.
 \end{multline*}
This inequality implies the result in lemma.
\end{proof}

\begin{comentario} Of course, the existence of the limit on the right hand side in equation \eqref{eq:lim-weak}   does not guarantee the existence of limit of $h(t)$ for $t\to\infty$. An example of this fact is obtained as follow. Let 
\[
 h=\sum_{n=0}^{\infty}\mathbbm{1}_{[n,n+\frac12]},
\]
where $\mathbbm{1}_{A}$ denotes the characteristic function of the set $A$.  Then $h(s)+h(s-\frac12)=1$, for $s\in [0,+\infty]$. 
We define $\varphi(s)=h(e^s-1)$. Then
\begin{multline}\label{eq:sum_1}
 1=\lim\limits_{t\to\infty}\gamma\int_0^t \left(\varphi(s)+\varphi\left(s-\frac12\right)
 \right) e^{\gamma (s-t)}ds\\=\lim\limits_{t\to\infty}\gamma\int_0^t\varphi(s)e^{\gamma (s-t)}ds+ \gamma\int_0^t \varphi\left(s-\frac12\right)
  e^{\gamma (s-t)}ds
\end{multline}
On the other hand
\begin{multline}\label{eq:tras_12}
 \gamma\int_0^t \varphi\left(s-\frac12\right)
  e^{\gamma (s-t)}ds= \gamma e^{\frac{\gamma}{2}}\int_0^{t-\frac12} \varphi\left(r\right)
  e^{\gamma (r-t)}dr\\=\gamma e^{\frac{\gamma}{2}}\int_0^{t} \varphi\left(r\right)
  e^{\gamma (r-t)}dr-
  \gamma e^{\frac{\gamma}{2}}\int_{t-\frac12}^{t} \varphi\left(r\right)
  e^{\gamma (r-t)}dr
\end{multline}

In my understanding
\[
\lim\limits_{t\to\infty} \int_{t-\frac12}^{t} \varphi\left(r\right)
  e^{\gamma (r-t)}dr= \frac{1}{2\gamma}(1-e^{-\gamma/2}).
\]

Taking account of \eqref{eq:sum_1}, \eqref{eq:tras_12} we infer that 
\[
\lim\limits_{t\to\infty} \gamma \int_{0}^{t} \varphi\left(s\right)
  e^{\gamma (s-t)}ds=\frac{e^{\gamma/2}}{2(1+e^{\gamma/2})}
\]


\end{comentario}

The following proposition to expresses the fact that epidemic is extinguished when $t\to\infty$ and, in certain sense, the total quantity of applied vaccines $\sigma_iS_i$ goes to zero when $t\to\infty$.   

\begin{prop} 
\[
 \lim\limits_{t\to\infty}\gamma\int_0^t \sigma_i(s)S_i(s)
  e^{\gamma (s-t)}ds=I_i(\infty)=0.
\]

 
\end{prop}

\begin{proof} Adding equations \eqref{eq:SIRmv1} and \eqref{eq:SIRmv2} we obtain 
\[
 (S_i+I_i)'=-\sigma_iS_i-\gamma I_i\leq 0.
\]
Therefore  $S_i+I_i$ is a monotone non increasing function. Hence $\lim_{t\to\infty} (S_i+I_i)$ there exists. From \eqref{eq:SIRmv1} the same considerations are true for function $S_i$. Consequently there exists $\lim_{t\to\infty} S_i(t)=:S_i(\infty)$. We deduce that there exists  $\lim_{t\to\infty} I_i(t)=:I_i(\infty)$. If $I(\infty)>0$, we could choose $t_0$ large enough for that $t\geq t_0$ implies $I_i(t)>I_i(\infty)/2=:a>0$. Then $(S_i(t)+I_i(t))'\leq -\gamma I_i(t)\leq -\gamma a$. This inequality implies that $S_i(t) +I_i(t)\to -\infty$, when $t\to\infty$, which is a contradiction. Consequently $I_i(\infty)=0$. 

 
From  \eqref{eq:SIRmv2} and \eqref{eq:1order} we obtain that


\[
\begin{split}
 I_i(t)&=e^{-\gamma t}
 \left\{
    I_i(0)+\int_0^t e^{\gamma s} S_{i}(s) \sum\limits_{j=1}^{n} \beta_{i j} I_{j}(s)ds
\right\}\\
&= e^{-\gamma t}
 \left\{
    I_i(0)-\int_0^t e^{\gamma s} \left[S'_i(s)+\sigma_i(s)S_i\right]ds 
  \right\}\\
  &= e^{-\gamma t}
 \left\{
    I_i(0)-\int_0^t e^{\gamma s}  \sigma_i(s)S_i(s)ds
    -e^{\gamma t}S_i(t)+S_i(0)-\gamma\int_0^t e^{\gamma s} S_{i}(s) ds 
  \right\}\\
   &= e^{-\gamma t}\left(S_i(0)+ I_i(0)  \right)-S_i(t)
   +\gamma \int_0^t e^{\gamma (s-t)}S_{i}(s)ds-\int_0^t e^{\gamma s}  \sigma_i(s)S_i(s)ds
 \end{split}
\]

Taking the limit for $t\to\infty$ in previous identities and using Lemma \ref{lem:lim-weak} 
\end{proof}


\begin{conj} 
 \[
 \lim\limits_{t\to\infty} \sigma_i(s)S_i(s)
=0.
\]

\end{conj}


\section{Existence minimizers}

In this Section, we prove that the optimal control problem (\ref{OptimalProblem}) has a solution. That is, we prove that the hypothesis of the Filippov-Cesari Theorem are satisfied (see \cite{A.Seierstad499}). In what follows, we will use the following notation
$$
x=\left(S_{1}, \ldots, S_{n}, I_{1}, \ldots, I_{n}, R_{1},\ldots, R_{n}\right)
$$
\[f_{0}\left(x_{i}, \sigma_{i}, t\right)=f_{0}\left(S_{1}, \ldots, S_{1}, I_{1}\ldots, I_n, R_{1}, \cdots, R_{n} ; \sigma_{1}, \cdots, \sigma_{n} ; t\right)=\sum_{i=1}^{n} I_{i}(t).\]
For $i=1,2,\cdots, n$, we denote by
$$
f_{i}=\left(f_{1 i}, f_{2 i}, f_{3 i}\right), \quad  f=\left(f_{1}, \ldots, f_{n}\right) 
$$
with
\[f_{1 i}=\mu N_{i}-S_{i}(t) \sum_{j=1}^{n} \beta_{i} I_{j}(t)-\delta \sigma_{i} S_{i}(t)-d S_{i}(t)\]
\[f_{2i}=S_{i}(t) \sum_{j=1}^{n} \beta_{i} I_{j}(t)-(d+\alpha+\gamma) I_{i}(t)\]
\[f_{3 i}=\gamma I_{i}(t)+\delta \sigma_{i} S_{i}(t)-d R_{i}(t)\]
and we define
$$N\left(x, U_{a d}, t\right)=\left\{\left(f_{0}+\gamma, f\right):\, \gamma \geq 0,\, \sigma \in U_{a d}\right\}.$$
Now, we will are in conditions to prove the following result.

\begin{thm}
The optimal control problem (\ref{OptimalProblem}) has a solution $\sigma^{*} \in U_{ad}$.
\end{thm}
\begin{proof}
We prove that $N(x, U_{a d}, t)$ is a convex set, for all $(x,t)$. 

Let 
$\left(a_{1}, b_{1}\right), \left(a_{2}, b_{2}\right) \in N\left(x, U_{a d}, t\right)$ be, then there exist $\gamma_{1}, \gamma_{2} \geq 0$ and $\sigma_{1}, \sigma_2 \in  U_{a d}$ such that 
$$
\left(f_{0}\left(x, \sigma_{1}, t\right)+\gamma_{1} ; f\left(x, \sigma_{1}, t\right)\right)=\left(a_{1}, b_{1}\right) 
$$
and
$$
\left(f_{0}\left(x, \sigma_{2}, t\right)+\gamma_{2}, f\left(x, \sigma_{2}, t\right)\right)=\left(a_{2}, b_{2}\right)
$$
then 
$$
\lambda\left(a_{1}, b_{1}\right)+(1-\lambda)\left(a_{2}, b_{2}\right)=\left(\lambda a_1+(1-\lambda) a_{2}, \lambda b_{1}+(1-\lambda) b_{2}\right)
$$
$$
=\left(\lambda\left(f_{0}\left(x, \sigma_{1}, t\right)+\gamma_{1}\right)+(1-\lambda)\left(f_{0}\left(x_{1}, \sigma_{2}, t\right)+\gamma_{2}\right), \lambda f\left(x, \sigma_{1}, t\right)+(1-\lambda) f\left(x,\sigma_{2}, t\right)\right).
$$
Now, we consider the second component
$$
\lambda f\left(x, \sigma_{1}, t\right)+(1-\lambda) f\left(x, \sigma_{2}, t\right)
$$
and from the linearity of $f$ with respect $\sigma$, we have 
\[\lambda f\left(x, \sigma_{1}, t\right)+(1-\lambda) f\left(x, \sigma_{2}, t\right)=f\left(x, \lambda \sigma_{1}+(1-\lambda) \sigma_{2}, t\right)\]
Moreover, $\overline{\sigma}=\lambda \sigma_{1}+(1-\lambda) \sigma_{2} \in U_{ad}$. In fact, $\lambda \sigma_{1}+(1-\lambda) \sigma_{2}$ is measurable, $\lambda \sigma_{1}+(1-\lambda) \sigma_{2} \geqslant 0$ and if we consider
$\sigma_{1}=\left(\sigma_{11}, \ldots \ldots, \sigma_{1 n}\right)$ and $ \sigma_{2}=\left(\sigma_{21} \ldots \ldots \sigma_{2 n}\right)$ in $U_{ad}$, then
\[
\lambda \sigma_{1}+(1-\lambda) \sigma_{2}=\left(\lambda \sigma_{11}+(1-\lambda) \sigma_{21}, \ldots,\lambda \sigma_{1 n}+(1-\lambda) \sigma_{2 n}\right)
\]
next
$$
\begin{array}{l}
\left(\lambda \sigma_{11}+(1-\lambda) \sigma_{21}\right)S_{1}+\cdots+\left(\lambda \sigma_{1n}+(1-\lambda) \sigma_{2n}\right)S_{n}=\\
\lambda\left(\sigma_{11}S_{1}+\cdots+\sigma_{1 n}S_{n}\right)+(1-\lambda)\left(\sigma_{21}S_{1}+\cdots+\tau_{2 n}S_{n}\right)\leq {\sigma}_{Tot}
\end{array}
$$
therefore $\lambda \sigma_{1}+(1-\lambda) \sigma_{2}\in U_{ad}$.

Now, we prove that there exists $\gamma \geq 0$ such that
$$f_{0}\left(x, \overline{\sigma}, t\right)+\gamma=\lambda a_{1}+(1-\lambda) a_{2}.$$
We note that $f_0$ is constant with respect to the control variable, then
$$
f_{0}\left(x, \lambda \sigma_{1}+(1-\lambda) \sigma_{2}, t\right)=\lambda f_{0}\left(x, \sigma_{1}, t\right)+(1-\lambda) f_{0}\left(x, \sigma_{2}, t\right).
$$
If we define $\gamma=\lambda \gamma_{1}+(1-\lambda) \gamma_{2} \geq 0$, we have that
$$
\begin{aligned}
f_{0}\left(x,\lambda \sigma_{1}+(1-\lambda) \sigma_{2}, t\right)+\gamma &=\left[\lambda f_{0}\left(x,\sigma_{1}, t\right)+(1-\lambda) f_{0}\left(x, \sigma_{2}, t\right)\right]+\left[(\lambda \gamma_{1}+(1-\lambda) \gamma_{2}\right] \\
&=\lambda f_{0}\left(x,\sigma_{1}, t\right)+\lambda \gamma_{1}+(1-\lambda) f_{0}\left(x, \sigma_{2}, t\right)+(1-\lambda) \gamma_{2} \\
&=\lambda\left(f_{0}\left(x, \sigma_{1}, t\right)+\gamma_{1}\right)+(1-\lambda)\left(f_{0}\left(x, \sigma_{2}, t\right)+\gamma_{2}\right) \\
&=\lambda a_{1}+(1-\lambda) a_{2}.
\end{aligned}
$$
Therefore, we proved that there exists 
$\gamma=\lambda \gamma_{1}+(1-\lambda) \gamma_{2} \geq 0$ and there exists $\overline{\sigma}=\lambda \sigma_{1}+(1-\lambda) \sigma_{2} \in U_{ad}$
such that 
$$\left(\lambda {a_{1}}+(1-\lambda) {a_{2}}, \lambda b_{1}+(1-\lambda) b_{2}\right)=\left(f_{0}\left(x, \overline{\sigma}, t\right)+\gamma , f\left(x, \overline{\sigma}, t\right)\right),$$
i.e.
$$\left(\lambda a_{1}+(1-\lambda) a_{2}, \lambda b_{1}+(1-\lambda) b_{2}\right) \in N\left(x, U_{ad}, t\right)$$
and $N\left(x, U_{a d}, t\right)$ is a convex set, for all fixed $(x,t)$.

Moreover, $U_{ad}$ is a compact set, since $0 \leq \sigma_{i} \leq \sigma_{\text {Tot }}, \forall i=1, \ldots, n$. Finally, taking into account that the number of susceptible, infected and removed individuals are bounded by the total quantity of individuals, we have that $\|x(t)\| \leqslant b$. Therefore, we have verified the hypothesis of Filippov-Cesari Existence Theorem and the thesis holds.
\end{proof}

\section{Optimality system}

In this Section, we obtain the optimality system, which is derived of the Pontryagin Maximum Principle. We define the Lagrangian by
\[
L=\sum_{i=1}^{n} I_{i}(t)
\]
and the Hamiltonian by
\[
H=L+\sum_{i=1}^{n} \left[\lambda_{1i}\frac{d S_{i}}{dt}+\lambda_{2i}\frac{d I_{i}}{dt}+\lambda_{3i}\frac{d R_{i}}{dt}\right] 
\]
where $\lambda_{1i}$, $\lambda_{2i}$ and $\lambda_{3i}$ are the adjoint variables to be determined suitably.

\begin{thm}
Let $(I^{*}, \sigma^{*})$ be a optimal solution for the optimal control problem (\ref{OptimalProblem}), where $I^{*}(t)=(I_{1}^{*}(t),\cdots, I_{n}^{*}(t))$ and $\sigma^{*}(t)=(\sigma_{1}^{*}(t),\cdots, \sigma_{n}^{*}(t))$. Then there exist adjoint variables $\lambda_{1i}$, $\lambda_{2i}$ and $\lambda_{3i}$ for $i=1,\cdots, n$, that satisfy
\begin{equation}\label{lambda1}
\frac{d\lambda_{1i}}{dt}=-\lambda_{1i}\left(\sum_{j=1}^{n} \beta_{i j} I_{j}(t)-\delta\sigma_{i}-d\right)-\lambda_{2i}\left(\sum_{j=1}^{n} \beta_{i j} I_{j}(t)\right)-\lambda_{3i}\delta\sigma_{i}
\end{equation}
\begin{equation}\label{lambda2}
\frac{d\lambda_{2i}}{dt}=-1-\lambda_{2i}\left(d+\alpha+\gamma\right)-\lambda_{3i}\gamma 
\end{equation}
\begin{equation}\label{lambda3}
\frac{d\lambda_{3i}}{dt}=\lambda_{3i}d
\end{equation}
with transversality conditions
\begin{equation}\label{transver}
\lambda_{1i}(T)=\lambda_{2i}(T)=\lambda_{3i}(T)=0
\end{equation}
Furthermore, the optimality equation is given by
\begin{equation}\label{OptimalityEquation}
(\lambda_{1i}-\lambda_{1i})\delta S_{i}^{*}=0.
\end{equation}
\end{thm}

\begin{proof}
We know, from the Pontryagin Maximum Principle (see \cite{Chen-2014}), that if $(I^{*}, \sigma^{*})$ is a optimal solution for the optimal control problem (\ref{OptimalProblem}), then there exists a vectorial function $\lambda(t)=(\lambda_{1}(t),\cdots,\lambda_{n}(t))$ satisfying the following equalities
\begin{equation*}
\left\{\begin{array}{l}\frac{d \lambda}{d t}=-\frac{\partial H(t,I^{*}(t)),\sigma^{*}(t),\lambda(t)}{\partial I}\\ 
\frac{\partial H(t,I^{*}(t)),\sigma^{*}(t),\lambda(t)}{\partial \sigma}=0 \\ 
\frac{d I}{d t}=-\frac{\partial H(t,I^{*}(t)),\sigma^{*}(t),\lambda(t)}{\partial \partial \lambda}.
\end{array}\right. 
\end{equation*}
Here, taking into account that
\[
H=\sum_{i=1}^{n} I_{i}(t)+\sum_{i=1}^{n} \left[\lambda_{1i}\frac{d S_{i}}{dt}+\lambda_{2i}\frac{d I_{i}}{dt}+\lambda_{3i}\frac{d R_{i}}{dt}\right] 
\]
we have
\[
\frac{d\lambda_{1i}}{dt}=-\frac{dH}{dS_{i}}=-\frac{dI_{i}}{dS_{i}}-\left[\lambda_{1i}\frac{\partial}{\partial S_{i}}(\frac{d S_{i}}{dt})+\lambda_{2i}\frac{\partial}{\partial S_{i}}(\frac{d I_{i}}{dt})+\lambda_{3i}\frac{\partial}{\partial S_{i}}(\frac{d R_{i}}{dt})\right] 
\]
\[
\frac{d\lambda_{2i}}{dt}=-\frac{dH}{dI_{i}}=-\frac{dI_{i}}{dI_{i}}-\left[\lambda_{1i}\frac{\partial}{\partial I_{i}}(\frac{d S_{i}}{dt})+\lambda_{2i}\frac{\partial}{\partial I_{i}}(\frac{d I_{i}}{dt})+\lambda_{3i}\frac{\partial}{\partial I_{i}}(\frac{d R_{i}}{dt})\right] 
\]
\[
\frac{d\lambda_{3i}}{dt}=-\frac{dH}{dR_{i}}=-\frac{dI_{i}}{dR_{i}}-\left[\lambda_{1i}\frac{\partial}{\partial R_{i}}(\frac{d S_{i}}{dt})+\lambda_{2i}\frac{\partial}{\partial R_{i}}(\frac{d I_{i}}{dt})+\lambda_{3i}\frac{\partial}{\partial R_{i}}(\frac{d R_{i}}{dt})\right] 
\]
that is, we obtain the equations (\ref{lambda1}), (\ref{lambda2}) and (\ref{lambda3}), with the transversality conditions (\ref{transver}). Moreover, the optimality equation is given by
\[
\frac{\partial H(t,I^{*}(t)),\sigma^{*}(t),\lambda(t))}{\partial\sigma}=0
\]
i.e.
\begin{equation*}
(\lambda_{1i}-\lambda_{1i})\delta S_{i}^{*}=0.
\end{equation*}
and the thesis holds.
\end{proof}


\begin{rem}
We note that the optimal control $\sigma^{*}$ is not explicit in the optimality equation (\ref{OptimalityEquation}).
\end{rem}







\section{Numerical results}  

..........................



  \bibliographystyle{apalike}
  \bibliography{control, epidemias, EpidemiologiaPapers,otros}

\end{document}
